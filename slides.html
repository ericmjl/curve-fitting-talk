<html>
  <head>
    <meta charset="UTF-8">
    <script type="text/javascript" src="./assets/revealjs/more/js/head.min.js"></script>
    <link rel="stylesheet" href="./assets/revealjs/css/reveal.css">
    <link rel="stylesheet" href="./assets/revealjs/css/theme/white.css">
    <!-- Next up, syntax highlighting. -->
    <link rel="stylesheet" href="./assets/revealjs/more/css/zenburn.css"/>
    <link rel="stylesheet" type="text/css" href="./assets/custom.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css">
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section id="introduction">
          <section id="title-slide">
            <h1>Fret Not, It's Curve Fitting All The Way Down!</h1>
            <img src="./assets/images/ericmjl.png" width="250px" align="left">
            <p align="right">"epiphanies in Bayes-land"</p>
            <p align="right">Eric J. Ma, Digility 2018</p>
          </section>
          <section id="follow-along">
            <h1>Follow Along!</h1>
            <p>
              <a href="https://ericmjl.github.io/curve-fitting-talk">ericmjl.github.io/
                <b>curve-fitting-talk</b>
              </a>
            </p>
            <p>
              <img src="./assets/images/talk.png" width="250px">
            </p>
          </section>
          <section id="about">
            <h1>About Myself</h1>
            <ul>
              <li class="fragment">Investigator, Scientific Data Analysis, NIBR</li>
              <li class="fragment">MIT Biological Engineering, ScD, 2017</li>
              <li class="fragment">Self-taught machine & deep learner, Bayesian Pythonista</li>
            </ul>
          </section>
          <section id="goals">
            <h1>Goals</h1>
            <ol>
              <li class="fragment">Demystify basic concepts in Bayesian statistical inference, using lots of pictures and minimal equations.</li>
              <li class="fragment">Show how Bayesian methods can help you design more reasonably.</li>
            </ol>
          </section>
          <section id="bayes-rule-neon-sign" data-background="./assets/images/bayes-rule-neon-sign.jpg">
          </section>
        </section>

        <section id="estimation">
          <section id="estimation-images">
            <h2>Estimation</h2>
            <img src="./assets/images/framework/estimation/data.png" width=20% class="fragment">
            <img src="./assets/images/framework/estimation/point.png" width=20% class="fragment">
            <img src="./assets/images/framework/estimation/distribution.png" width=20% class="fragment">
            <img src="./assets/images/framework/estimation/hierarchical.png" width=20% class="fragment">
          </section>
          <section id="estimation-model-diagram">
            <img src="./assets/images/framework/estimation/model.png" alt="" width=70%>
          </section>
          <section id="estimation-code">
            <pre>
              <code data-trim data-noescape class="py">
                import numpy as np
                import pymc3 as pm

                data = np.random.normal(loc=6, sd=2, size=1000)
                with pm.Model() as model:
                    # Priors
                    sd = pm.Exponential('sd', lam=5)
                    mu = pm.Normal('mu', mu=0, sd=100)

                    # Likelihood for data
                    like = pm.Normal('like', mu=mu, sd=sd, observed=data)
              </code>
            </pre>
          </section>
        </section>

        <section id="linreg">
          <section id="linreg-images">
            <h2>Linear Regression</h2>
            <img src="./assets/images/framework/linreg/data.png" width=20% class="fragment">
            <img src="./assets/images/framework/linreg/point.png" width=20% class="fragment">
            <img src="./assets/images/framework/linreg/distribution.png" width=20% class="fragment">
            <img src="./assets/images/framework/linreg/hierarchical.png" width=20% class="fragment">
          </section>
          <section id="linreg-model-diagram">
            <img src="./assets/images/framework/linreg/model.png" alt="" width=80%>
          </section>
          <section id="linreg-code">
            <pre>
              <code data-trim data-noescape class="py">
                import pymc3 as pm
                import numpy as np

                x = np.random.normal(loc=0, sd=10, size=1000)
                m = 10; c = 6;
                y = m * x + c + np.random.normal(0, 0.2)

                with pm.Model() as model:
                    # Priors
                    m = pm.Normal('m', loc=0, sd=100)
                    c = pm.Normal('c', loc=0, sd=100)
                    sd = pm.Exponential('sd', lam=5)

                    # Link function
                    mu = m * x + c

                    # Likelihood for data
                    like = pm.Normal('like', mu=mu, sd=sd, observed=y)
              </code>
            </pre>
          </section>
        </section>

        <section id="logreg">
          <section id="logreg-images">
            <h2>Logistic regression</h2>
            <img src="./assets/images/framework/logreg/data.png" width=20% class="fragment">
            <img src="./assets/images/framework/logreg/point.png" width=20% class="fragment">
            <img src="./assets/images/framework/logreg/distribution.png" width=20% class="fragment">
            <img src="./assets/images/framework/logreg/hierarchical.png" width=20% class="fragment">
          </section>
          <section id="logreg-model-diagram">
            <img src="./assets/images/framework/logreg/model.png" alt="" width=40%>
          </section>
          <section id="logreg-code">
            <pre>
              <code data-trim data-noescape class="py">
                import pymc3 as pm
                import numpy as np

                with pm.Model() as model:
                    # Priors
                    beta = pm.Normal('beta', mu=0, sd=100)

                    # Link function
                    p = 1 / (1 + beta * x)

                    # Likelihood for data
                    like = pm.Bernoulli('like', p=p, observed=data)
              </code>
            </pre>
          </section>
        </section>

        <section id="curves">
          <section id="curves-images">
            <h2>Parametric Curves</h2>
            <img src="./assets/images/framework/curves/data.png" width=20% class="fragment">
            <img src="./assets/images/framework/curves/point.png" width=20% class="fragment">
            <img src="./assets/images/framework/curves/distribution.png" width=20% class="fragment">
            <img src="./assets/images/framework/curves/hierarchical.png" width=20% class="fragment">
          </section>
          <section id="curves-diagram">
            <img src="./assets/images/framework/curves/model.png" alt="">
          </section>
          <section id="curves-code">
            <pre>
              <code data-trim data-noescape class="py">
                import pymc3 as pm
                import numpy as np

                with pm.Model() as model:
                    # Priors
                    A = pm.HalfNormal('A', sd=100)
                    b = pm.Normal('b', mu=0, sd=100)
                    C = pm.HalfNormal('C', sd=100)
                    sd = pm.Exponential('sd', lam=5)

                    # Link function
                    mu = A * tt.exp(-b * x) + C

                    # Likelihood for data
                    like = pm.Normal('like', mu=mu, lam=lam, observed=data)
              </code>
            </pre>
          </section>
        </section>

        <section id="nn">
          <section id="nn-images">
            <h2>Neural Networks</h2>
            <img src="./assets/images/framework/nn/data.png" width=20% class="fragment">
            <img src="./assets/images/framework/nn/point.png" width=20% class="fragment">
            <img src="./assets/images/framework/nn/distribution.png" width=20% class="fragment">
            <img src="./assets/images/framework/nn/hierarchical.png" width=20% class="fragment">
          </section>
          <section id="nn-diagram">
            <img src="./assets/images/framework/nn/model.png" alt="" width=80%>
          </section>
          <section id="nn-code">
            <pre>
              <code data-trim data-noescape class="py">
                def nn(x):
                    w1 = pm.Normal('w1', mu=0, sd=1, shape=(x.shape[1], x.shape[1]))
                    b1 = pm.Normal('b1', mu=0, sd=1, shape=(x.shape[1]))
                    a1 = tt.tanh(tt.dot(x, w1) + b1)

                    w2 = pm.Normal('w2', mu=0, sd=1, shape=(x.shape[1], 1))
                    b2 = pm.Normal('b2', mu=0, sd=1, shape=(1,))
                    a2 = tt.tanh(tt.dot(a1, w2) + b2)

                    return a2

                with pm.Model() as model:
                    mu = nn(x)
                    sd = pm.Exponential('sd', lam=5)
                    like = pm.Normal('like', mu=mu, sd=sd, observed=data)
              </code>
            </pre>
          </section>
          <section id="nn-question">
            <h1>But what exactly is a neural network?</h1>
          </section>
          <section id="nn-infographic">
            <img src="./assets/images/framework/nn/nn-matrices.png" alt="" width=70%>
          </section>
          <section id="nn-answer">
            <p class="fragment">Deep neural networks are nothing more than matrix transformations on input data.</p>
            <p class="fragment"><i>They are nothing more than fancy curve fitters!</i></p>
          </section>
          <section id="nn-more-info">
            <p>For more details and pretty pictures, check out another talk I did at <a href="https://www.youtube.com/watch?v=s0S6HFdPtlA">PyData NYC 2017</a>!</p>
            <iframe width="800" height="400" src="https://www.youtube.com/embed/s0S6HFdPtlA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </section>
        </section>
        <section id="design">
          <section id="design-title-slide">
            <h2>How can Bayesian methods can help you design more reasonably?</h2>
            <p class="fragment">By "reasonably", we mean "in a way that doesn't violate common statistical sense".</p>
          </section>
        </section>
        <section id="hockey">
          <section id="hockey-title-slide">
            <p>How do we quantify ice hockey goaltender performance?</p>
            <img src="./assets/images/design/jacob-markstrom.jpg" alt="">
            <p style="font-size:15">
              <caption>Image from
                <a href="http://forum.canucks.com/topic/379072-nhl-goalie-rankings-5/">Canucks forums</a>.
              </caption>
            </p>
          </section>
          <section id="hockey-goalie-stats">
            <table>
              <tr>
                <th>ID</th>
                <th>Goals Against</th>
                <th>Goals Saved</th>
                <th>Save Percentage</th>
              </tr>
              <tr class="fragment">
                <td>Jake Allen</td>
                <td>1614</td>
                <td>1462</td>
                <td class="fragment">0.906</td>
              </tr>
              <tr class="fragment">
                <td>Dylan Ferguson</td>
                <td>2</td>
                <td>1</td>
                <td class="fragment">0.500</td>
              </tr>
              <tr class="fragment">
                <td>Scott Foster</td>
                <td>7</td>
                <td>7</td>
                <td class="fragment">1.000</td>
              </tr>
            </table>
            <p>Who is the better goalie?</p>
          </section>
          <section id="hockey-model-naive">
            <img src="./assets/images/design/baseball-model.png" alt="" width=30% align="right">
            <p class="fragment" align="left">Each player is estimated <b>independently</b>.</p>
            <p class="fragment" align="left"><b>beta distribution</b> tells us how uncertain we are about a probability parameter.</p>
            <p class="fragment" align="left"><b>binomial distribution</b> gives us the <i>likelihood function</i> for the data.</p>
          </section>
          <section id="hockey-model-code">
            <pre>
              <code data-trim data-noescape class="py">
                 with pm.Model() as nopool:
                    n_players = len(df)
                    p = pm.Beta('p', alpha=1, beta=1, shape=(n_players,))
                    like = pm.Binomial('likelihood',
                                       n=df['SA'],
                                       p=p,
                                       observed=df['SV'])
              </code>
            </pre>
          </section>
          <section>
            {{ elements['hockey_unpooled_div'] }}
            {{ elements['hockey_unpooled_script'] }}
            <p class="fragment">Is Dylan Ferguson really that bad?</p>
          </section>
          <section>
            <h1>Let's try again</h1>
          </section>
          <section id="hockey-model-hierarchical">
            <img src="./assets/images/design/baseball-hierarchical-model.png" alt="" width="45%" align="right">
            <p class="fragment" align="left"><b>beta distribution</b>: <i>α</i> is "number of successes", while <i>β</i> is "number of failures.</p>
            <p class="fragment" align="left"><b>hyperpriors</b>: <i>φ</i> is a "population" success probability, while <i>κ</i> models total number of data points.</p>
            <p class="fragment" align="left"><b>Expresses that players follow a population distribution.</b></p>
          </section>
          <section id="hockey-model-hierarchical-code">
            <pre>
              <code data-trim data-noescape class="py">
                with pm.Model() as pool:
                    n_players = len(df)

                    phi = pm.Uniform('phi', lower=0.0, upper=1.0)
                    kappa_log = pm.Exponential('kappa_log', lam=1.5)
                    kappa = pm.Deterministic('kappa', tt.exp(kappa_log))

                    p = pm.Beta('p', alpha=phi*kappa,
                                beta=(1.0-phi)*kappa,
                                shape=(n_players,))

                    like = pm.Binomial('likelihood',
                                       n=df['SA'],
                                       p=p,
                                       observed=df['SV'])
              </code>
            </pre>

          </section>
          <section>
            {{ elements['hockey_pooled_div'] }}
            {{ elements['hockey_pooled_script'] }}
            <p class="fragment">We believe that players without much data should be considered average, but with high uncertainty.</p>
          </section>
          <section>
            {{ elements['hockey_shrinkage_script'] }}
            {{ elements['hockey_shrinkage_div'] }}
            <p>With Bayesian partial pooling, we can impose reasonable prior knowledge about players on the modelling procedure.</p>
          </section>
          <section id="hockey-design">
            <h2>Some pointers</h2>
            <ol>
              <li>Average user: won't parse raw numbers well.</li>
              <li>Models should incorporate reasonable prior information.</li>
              <li>Uncertainty expresses confidence.</li>
            </ol>
          </section>
        </section>
        <section id="epiphanies">
          <section id="epiphanies-title-slide">
            <h1>Epiphanies in Bayes-land</h1>
          </section>
          <section id="reflections-on-ml">
            {{ elements['hockey_combined_div'] }}
            {{ elements['hockey_combined_script'] }}
            <p>Bayesian methods can help us design more reasonably.</p>
          </section>
          <section id="reflections-on-ml-2">
            <img src="./assets/images/bayesian-framework.png" alt="" width=55%>
            <p>Fret not, it's curve fitting...</p>
          </section>
          <section id="reflections-on-ml-3">
            <img src="./assets/images/all-the-way-down.png" alt="">
            <p>...all the way down! 😄</p>
          </section>
        </section>
        <section id="thank-you">
          <section>
            <h1>Thank you, Digility!</h1>
          </section>
        </section>
      </div>
    </div>
    <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js"></script>
    <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js"></script>
    <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js"></script>
    <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-api-0.13.0.min.js"></script>
    <script src="./assets/revealjs/js/reveal.js"></script>
    <script type="text/javascript">
      Reveal.initialize({
        history: true,
        dependencies: [
                    // Syntax highlight for <code> elements
                    { src: './assets/revealjs/plugin/highlight/highlight.js',
                      async: true,
                      callback: function() { hljs.initHighlightingOnLoad(); } },
                ]
      });
    </script>
  </body>
</html>
